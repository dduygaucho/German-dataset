{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First project in German.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2KGH0hL23Ob",
        "outputId": "d8f160c7-7ac1-4e2f-9900-a38eaef7f327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "X_train.shape:  (60000, 28, 28)\n",
            "y_train.shape:  (60000,)\n",
            "X_test.shape:  (10000, 28, 28)\n",
            "y_test.shape:  (10000,)\n",
            "(28, 28)\n",
            "Epoch 1/2\n",
            "750/750 [==============================] - 30s 24ms/step - loss: 0.2331 - accuracy: 0.9376 - val_loss: 0.1255 - val_accuracy: 0.9637\n",
            "Epoch 2/2\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.0761 - val_accuracy: 0.9757\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9748\n",
            "[0.0792427510023117, 0.9747999906539917]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "\n",
        "# flatten out as a vector\n",
        "# this is a sequential approach\n",
        "seq_model = keras.Sequential([\n",
        "    Input(shape = (28,28,1)),\n",
        "    Conv2D(32, (3,3), activation= 'relu'),  # there are 32 filters, which are 3x3 size\n",
        "    Conv2D(64, (3,3), activation= 'relu'),\n",
        "    MaxPool2D(),  # look for the best value\n",
        "    BatchNormalization(momentum= 0.99),\n",
        "\n",
        "    Conv2D(128, (3,3), activation= 'relu'),\n",
        "    MaxPool2D(),\n",
        "    BatchNormalization(), # normalise the batch to prevent vanishing exploding\n",
        "\n",
        "    GlobalAvgPool2D(),\n",
        "    Dense(64, activation= 'relu'),\n",
        "    Dense(10, activation= 'softmax')\n",
        "])\n",
        "\n",
        "# functional approach\n",
        "def functional_model():\n",
        "\n",
        "    my_input = Input(shape = (28,28,1))\n",
        "    x = Conv2D(32, (3,3), activation= 'relu')(my_input) # there are 32 filters, which are 3x3 size\n",
        "    x = Conv2D(64, (3,3), activation= 'relu')(x)\n",
        "    x = MaxPool2D()(x)  # look for the best value\n",
        "    x = BatchNormalization(momentum= 0.99)(x)\n",
        "\n",
        "    x = Conv2D(128, (3,3), activation= 'relu')(x)\n",
        "    x = MaxPool2D()(x)\n",
        "    x = BatchNormalization()(x) # normalise the batch to prevent vanishing exploding\n",
        "\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    x = Dense(64, activation= 'relu')(x)\n",
        "    x = Dense(10, activation= 'softmax')(x)\n",
        "\n",
        "    model = keras.models.Model(inputs = my_input, outputs = x)\n",
        "\n",
        "    return model\n",
        "\n",
        "# inherit from a class\n",
        "class MyCustomeModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = Conv2D(32, (3,3), activation= 'relu')  # there are 32 filters, which are 3x3 size\n",
        "    self.conv2 = Conv2D(64, (3,3), activation= 'relu')\n",
        "    self.maxpool1 = MaxPool2D()  # look for the best value\n",
        "    self.batchnorm1 = BatchNormalization(momentum= 0.99)\n",
        "\n",
        "    self.conv3 = Conv2D(128, (3,3), activation= 'relu')\n",
        "    self.maxpool2 = MaxPool2D()\n",
        "    self.batchnorm2 = BatchNormalization() # normalise the batch to prevent vanishing exploding\n",
        "\n",
        "    self.globalavgpool1 = GlobalAvgPool2D()\n",
        "    self.dense1 = Dense(64, activation= 'relu')\n",
        "    self.dense2 = Dense(10, activation= 'softmax')\n",
        "  \n",
        "  def call(self, my_input):\n",
        "    x = self.conv1(my_input)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.batchnorm1(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "\n",
        "    x = self.globalavgpool1(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def display_some_examples(examples, labels):\n",
        "    plt.figure(figsize = (10,10))\n",
        "    for i in range(25):\n",
        "        index = np.random.randint(0, examples.shape[0]-1) # lower end and higher end\n",
        "        img = examples[index]\n",
        "        label = labels[index]\n",
        "        plt.subplot(5,5, i+1) # row, column, and index\n",
        "        plt.title(str(label))\n",
        "        plt.imshow(img, cmap = 'gray')\n",
        "        plt.tight_layout()\n",
        "        plt.grid(visible=None)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    print(\"X_train.shape: \", X_train.shape)\n",
        "    print(\"y_train.shape: \", y_train.shape)\n",
        "    print(\"X_test.shape: \", X_test.shape)\n",
        "    print(\"y_test.shape: \", y_test.shape)\n",
        "    print(X_train[0].shape)\n",
        "    # print(tf.version)\n",
        "\n",
        " \n",
        "    X_train = X_train.astype('float32')/255\n",
        "    X_test = X_test.astype('float32')/255\n",
        "\n",
        "    X_train = np.expand_dims(X_train, axis =-1)\n",
        "    X_test = np.expand_dims(X_test, axis=-1)\n",
        "    # categorical will be used for one hot encoding\n",
        "    # otherwise for categorical use sparse\n",
        "\n",
        "    # Onehot encoding\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, 10) # how many classes are there\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    # replace seq_model with model\n",
        "    model = functional_model()\n",
        "\n",
        "    # using subclass\n",
        "    model = MyCustomeModel()\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, batch_size = 64, epochs = 2, validation_split = 0.2)\n",
        "\n",
        "    print(model.evaluate(X_test, y_test, batch_size = 64))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "plt.imshow(X_test[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yn7cvBnr280M",
        "outputId": "3b728d7f-a7f4-4155-f236-9b80e4f35633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbf2e048d50>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/dduygaucho/German-dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kalAddRU2_lc",
        "outputId": "b1d120e5-750d-4754-b54b-77f7be5408b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'German-dataset'...\n",
            "remote: Enumerating objects: 51950, done.\u001b[K\n",
            "remote: Counting objects: 100% (12695/12695), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12688/12688), done.\u001b[K\n",
            "remote: Total 51950 (delta 8), reused 12693 (delta 6), pack-reused 39255\u001b[K\n",
            "Receiving objects: 100% (51950/51950), 299.45 MiB | 13.82 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "Checking out files: 100% (51887/51887), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x6DQkkbQ4DH3",
        "outputId": "d3c7ddbf-a151-4c61-9898-1a981a702121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('German-dataset')"
      ],
      "metadata": {
        "id": "1a9x3zBq4Ujo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fnzv9z8j4fX_",
        "outputId": "71bfe6bd-1f4c-4060-e2e3-e4628a3398f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/German-dataset'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('training_data')"
      ],
      "metadata": {
        "id": "_Fibchh542kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"training_data\")\n",
        "os.mkdir('training')\n",
        "os.mkdir('validation')"
      ],
      "metadata": {
        "id": "Mz8w6ZAh5mV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import shutil\n",
        "\n",
        "def split_data(path_to_data, path_to_save_train, path_to_save_val,  split_size = 0.1):\n",
        "  folders = os.listdir(path_to_data)\n",
        "\n",
        "  for folder in folders:\n",
        "\n",
        "    full_path = os.path.join(path_to_data, folder) #  create a full path to the folder inside\n",
        "    images_path = glob.glob(os.path.join(full_path, '*.png')) # find png files recursively in the full_path folder\n",
        "\n",
        "    X_train, X_val = train_test_split(images_path, test_size = split_size)\n",
        "\n",
        "    for x in X_train:\n",
        "      path_to_folder = os.path.join(path_to_save_train, folder) # create a brand new folder in the new folder to prevent modifying raw files\n",
        "\n",
        "      if not os.path.isdir(path_to_folder):\n",
        "        os.makedirs(path_to_folder)\n",
        "      \n",
        "      shutil.copy(x, path_to_folder) # saving files into the new folder\n",
        "\n",
        "    for x in X_val:\n",
        "      path_to_folder = os.path.join(path_to_save_val, folder) # create a brand new folder in the new folder to prevent modifying raw files\n",
        "\n",
        "      if not os.path.isdir(path_to_folder):\n",
        "        os.makedirs(path_to_folder)\n",
        "      \n",
        "      shutil.copy(x, path_to_folder) # saving files into the new folder\n",
        "      \n",
        "if __name__ == '__main__':\n",
        "  path_to_data = \"/content/German-dataset/Train\"\n",
        "  path_to_save_train = \"/content/German-dataset/training_data/training\"\n",
        "  path_to_save_val = \"/content/German-dataset/training_data/validation\" \n",
        "  split_data(path_to_data, path_to_save_train, path_to_save_val)\n"
      ],
      "metadata": {
        "id": "nXdhCcbQ5wRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import shutil\n",
        "def order_test_set(path_to_images, path_to_csv):\n",
        "  \"\"\"\n",
        "  path_to_images: direction to images \n",
        "  path_to_csv: the csv file that used for checking test set: test.csv\n",
        "  Aim: want to organise the test folder exactly the same like in training_data/training or validation\n",
        "  \"\"\"\n",
        "  try:\n",
        "    with open (path_to_csv, 'r') as csvfile:\n",
        "      reader = csv.reader(csvfile, delimiter = ',')\n",
        "\n",
        "      for i, row in enumerate(reader):\n",
        "        if i == 0:\n",
        "          continue\n",
        "\n",
        "        img_name = row[-1].replace('Test/', '')\n",
        "        label = row[-2]\n",
        "\n",
        "        path_to_folder = os.path.join(path_to_images, label)\n",
        "        if not os.path.isdir(path_to_folder):\n",
        "          os.makedirs(path_to_folder)\n",
        "\n",
        "        img_full_path = os.path.join(path_to_images, img_name)\n",
        "        shutil.move(img_full_path, path_to_folder)\n",
        "\n",
        "  except:\n",
        "    print('[INFO]: Error in reading csv file')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  path_to_images = \"/content/German-dataset/Test\"\n",
        "  path_to_csv = \"/content/German-dataset/Test.csv\"\n",
        "  order_test_set(path_to_images, path_to_csv)\n"
      ],
      "metadata": {
        "id": "JXa8_ZVcMSOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, Flatten, GlobalAvgPool2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "# flatten out as a vector\n",
        "# this is a sequential approach\n",
        "seq_model = keras.Sequential([\n",
        "    Input(shape = (28,28,1)),\n",
        "    Conv2D(32, (3,3), activation= 'relu'),  # there are 32 filters, which are 3x3 size\n",
        "    Conv2D(64, (3,3), activation= 'relu'),\n",
        "    MaxPool2D(),  # look for the best value\n",
        "    BatchNormalization(momentum= 0.99),\n",
        "\n",
        "    Conv2D(128, (3,3), activation= 'relu'),\n",
        "    MaxPool2D(),\n",
        "    BatchNormalization(), # normalise the batch to prevent vanishing exploding\n",
        "\n",
        "    GlobalAvgPool2D(),\n",
        "    Dense(64, activation= 'relu'),\n",
        "    Dense(10, activation= 'softmax')\n",
        "])\n",
        "\n",
        "# functional approach\n",
        "def functional_model():\n",
        "\n",
        "    my_input = Input(shape = (28,28,1))\n",
        "    x = Conv2D(32, (3,3), activation= 'relu')(my_input) # there are 32 filters, which are 3x3 size\n",
        "    x = Conv2D(64, (3,3), activation= 'relu')(x)\n",
        "    x = MaxPool2D()(x)  # look for the best value\n",
        "    x = BatchNormalization(momentum= 0.99)(x)\n",
        "\n",
        "    x = Conv2D(128, (3,3), activation= 'relu')(x)\n",
        "    x = MaxPool2D()(x)\n",
        "    x = BatchNormalization()(x) # normalise the batch to prevent vanishing exploding\n",
        "\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    x = Dense(64, activation= 'relu')(x)\n",
        "    x = Dense(10, activation= 'softmax')(x)\n",
        "\n",
        "    model = keras.models.Model(inputs = my_input, outputs = x)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# inherit from a class\n",
        "class MyCustomeModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = Conv2D(32, (3,3), activation= 'relu')  # there are 32 filters, which are 3x3 size\n",
        "    self.conv2 = Conv2D(64, (3,3), activation= 'relu')\n",
        "    self.maxpool1 = MaxPool2D()  # look for the best value\n",
        "    self.batchnorm1 = BatchNormalization(momentum= 0.99)\n",
        "\n",
        "    self.conv3 = Conv2D(128, (3,3), activation= 'relu')\n",
        "    self.maxpool2 = MaxPool2D()\n",
        "    self.batchnorm2 = BatchNormalization() # normalise the batch to prevent vanishing exploding\n",
        "\n",
        "    self.globalavgpool1 = GlobalAvgPool2D()\n",
        "    self.dense1 = Dense(64, activation= 'relu')\n",
        "    self.dense2 = Dense(10, activation= 'softmax')\n",
        "  \n",
        "  def call(self, my_input):\n",
        "    x = self.conv1(my_input)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.batchnorm1(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "\n",
        "    x = self.globalavgpool1(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def street_signs_model(number_classes):\n",
        "  my_input = Input(shape = [60,60, 3]) # choose 60 as a mean of total number of images, typically choose mean/median of the image\n",
        "  # 3 is because there are 3 layers: R,G,B\n",
        "\n",
        "  x = Conv2D(32, (3,3), activation= 'relu')(my_input) # there are 32 filters, which are 3x3 size\n",
        "  x = MaxPool2D()(x)  # look for the best value\n",
        "  x = BatchNormalization(momentum= 0.99)(x)\n",
        "\n",
        "  x = Conv2D(64, (3,3), activation= 'relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x) # normalise the batch to prevent vanishing exploding\n",
        "\n",
        "  x = Conv2D(128, (3,3), activation= 'relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = BatchNormalization()(x) # normalise the batch to prevent vanishing exploding\n",
        "\n",
        "  #x = Flatten()(x) # Flatten out as a 1d vector\n",
        "  x = GlobalAvgPool2D()(x) # Output the last element of the previous BN/ either use flatten or globalavgpool\n",
        "  x = Dense(128, activation= 'relu')(x) \n",
        "  x = Dense(number_classes, activation= 'softmax')(x)\n",
        "\n",
        "  model = keras.models.Model(inputs = my_input, outputs = x)\n",
        "  # model = Model(... )\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def display_some_examples(examples, labels):\n",
        "    plt.figure(figsize = (10,10))\n",
        "    for i in range(25):\n",
        "        index = np.random.randint(0, examples.shape[0]-1) # lower end and higher end\n",
        "        img = examples[index]\n",
        "        label = labels[index]\n",
        "        plt.subplot(5,5, i+1) # row, column, and index\n",
        "        plt.title(str(label))\n",
        "        plt.imshow(img, cmap = 'gray')\n",
        "        plt.tight_layout()\n",
        "        plt.grid(visible=None)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    print(\"X_train.shape: \", X_train.shape)\n",
        "    print(\"y_train.shape: \", y_train.shape)\n",
        "    print(\"X_test.shape: \", X_test.shape)\n",
        "    print(\"y_test.shape: \", y_test.shape)\n",
        "    print(X_train[0].shape)\n",
        "    # print(tf.version)\n",
        "\n",
        " \n",
        "    X_train = X_train.astype('float32')/255\n",
        "    X_test = X_test.astype('float32')/255\n",
        "\n",
        "    X_train = np.expand_dims(X_train, axis =-1)\n",
        "    X_test = np.expand_dims(X_test, axis=-1)\n",
        "    # categorical will be used for one hot encoding\n",
        "    # otherwise for categorical use sparse\n",
        "\n",
        "    # Onehot encoding\n",
        "    # y_train = tf.keras.utils.to_categorical(y_train, 10) # how many classes are there\n",
        "    # y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    # replace seq_model with model\n",
        "    model = functional_model()\n",
        "\n",
        "    # using subclass\n",
        "    model = MyCustomeModel()\n",
        "    # model = street_signs_model(10)\n",
        "    # sparse = categorical\n",
        "    model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics = ['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, batch_size = 64, epochs = 2, validation_split = 0.2)\n",
        "\n",
        "    print(model.evaluate(X_test, y_test, batch_size = 64))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e7_wmeadXLn",
        "outputId": "6d84e349-cffd-4cc8-c486-12f4626063e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape:  (60000, 28, 28)\n",
            "y_train.shape:  (60000,)\n",
            "X_test.shape:  (10000, 28, 28)\n",
            "y_test.shape:  (10000,)\n",
            "(28, 28)\n",
            "Epoch 1/2\n",
            "750/750 [==============================] - 14s 17ms/step - loss: 0.2355 - accuracy: 0.9378 - val_loss: 0.2823 - val_accuracy: 0.9034\n",
            "Epoch 2/2\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.0590 - accuracy: 0.9826 - val_loss: 0.0882 - val_accuracy: 0.9708\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0877 - accuracy: 0.9709\n",
            "[0.08771034330129623, 0.9708999991416931]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU_QFCA1cg3u",
        "outputId": "589adf1e-b4db-403f-d9ac-194541e9a384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping # stop the training if there is no improvement\n",
        "\n",
        "def create_generators(batch_size, train_data_path, val_data_path, test_data_path):\n",
        "  preprocessor = ImageDataGenerator(\n",
        "      rescale = 1/255.                             # rescale data before putting in the machine learning model\n",
        "      # rotation_range = 10 # (rotated by -10 to 10 degrees)\n",
        "      # width_shift_range = 0.1 #  (shift the image 10% to left and right)\n",
        "  )\n",
        "  # should create 2 versions of preprocessor: train_processor and test_processor\n",
        "  # test for real application, and train for some hyperparams to tune such as rotation_range\n",
        "\n",
        "  train_generator = preprocessor.flow_from_directory(\n",
        "      train_data_path,  # go in this folder and knows automatically that every subfolder in this folder belongs to a single class\n",
        "      class_mode = 'categorical', # or sparse but for categorical it needs to be one-hot encoded\n",
        "      target_size = (60,60), # all images are resized to 60, 60\n",
        "      color_mode = 'rgb',\n",
        "      shuffle = True, # each epoch, batch images will be shuffled so that order does not matter when training\n",
        "      batch_size = batch_size\n",
        "\n",
        "  )\n",
        "\n",
        "  val_generator = preprocessor.flow_from_directory(\n",
        "      val_data_path,  # go in this folder and knows automatically that every subfolder in this folder belongs to a single class\n",
        "      class_mode = 'categorical', # or sparse but for categorical it needs to be one-hot encoded\n",
        "      target_size = (60,60), # all images are resized to 60, 60\n",
        "      color_mode = 'rgb',\n",
        "      shuffle = False, # each epoch, batch images will be shuffled so that order does not matter when training\n",
        "      batch_size = batch_size\n",
        "\n",
        "  )\n",
        "\n",
        "  test_generator = preprocessor.flow_from_directory(\n",
        "      test_data_path,  # go in this folder and knows automatically that every subfolder in this folder belongs to a single class\n",
        "      class_mode = 'categorical', # or sparse but for categorical it needs to be one-hot encoded\n",
        "      target_size = (60,60), # all images are resized to 60, 60\n",
        "      color_mode = 'rgb',\n",
        "      shuffle = False, # no matter when testing or validating\n",
        "      batch_size = batch_size\n",
        "  )\n",
        "  return train_generator, val_generator, test_generator\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  path_to_train = \"/content/German-dataset/training_data/training\"\n",
        "  path_to_val = \"/content/German-dataset/training_data/validation\"\n",
        "  path_to_test = \"/content/German-dataset/Test\"\n",
        "  batch_size = 64\n",
        "  epochs = 15\n",
        "  lr = learning_rate\n",
        "  path_to_save_model = './Models'\n",
        "  train_generator, val_generator, test_generator = create_generators(batch_size, path_to_train, path_to_val, path_to_test)\n",
        "  number_classes = train_generator.num_classes\n",
        "  TRAIN = False\n",
        "  TEST = True\n",
        "  if TRAIN:\n",
        "    ckpt_saver = ModelCheckpoint(\n",
        "        path_to_save_model,\n",
        "        monitor = 'val_accuracy', # monitor this value\n",
        "        mode = 'max', # achieve the highest and save\n",
        "        save_best_only = True, # only save the best model only\n",
        "        save_freq = 'epoch',\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor = 'val_accuracy', \n",
        "        patience = 10\n",
        "    )\n",
        "\n",
        "    model = street_signs_model(number_classes)\n",
        "    # optimizer = tf.keras.optimizers.SGD(learning_rate = lr, amsgrad = True) #grad: better\n",
        "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    model.fit(train_generator, epochs= epochs, batch_size= batch_size,\n",
        "              validation_data = val_generator,\n",
        "              callbacks = [ckpt_saver, early_stop])\n",
        "    \n",
        "  if TEST:\n",
        "    model = tf.keras.models.load_model('./Models')\n",
        "    model.summary()\n",
        "    print(\"Evaluating the validation set\")\n",
        "    model.evaluate(val_generator)\n",
        "    print(\"Evaluating the test set\")\n",
        "    model.evaluate(test_generator)\n",
        "\n",
        "\n",
        "# Parameters to change to improve: epochs, batch_size, architecture of layers\n",
        "# Can add other things to the preprocessing: data augmentation techniques\n",
        "# changing the learning rate from the optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FONe1uKQjqyt",
        "outputId": "43ebcbef-b332-4b15-e5b0-a06f17cdf55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 38791 images belonging to 43 classes.\n",
            "Found 7424 images belonging to 43 classes.\n",
            "Found 12630 images belonging to 43 classes.\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 60, 60, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 58, 58, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 29, 29, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 29, 29, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 27, 27, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 13, 13, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 13, 13, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 11, 11, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 5, 5, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 5, 5, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling2d_13  (None, 128)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 43)                5547      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,203\n",
            "Trainable params: 115,755\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Evaluating the validation set\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0039 - accuracy: 0.9992\n",
            "Evaluating the test set\n",
            "198/198 [==============================] - 7s 34ms/step - loss: 0.1580 - accuracy: 0.9652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wpSgNiGtpFGA",
        "outputId": "7ab20d8f-3bff-425e-8bc4-7bc266172e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/German-dataset'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_model(model, imgpath):\n",
        "  image = tf.io.read_file(imgpath)\n",
        "  image = tf.image.decode_png(image, channels = 3)\n",
        "  image = tf.image.convert_image_dtype(image, dtype = tf.float32)\n",
        "  image = tf.image.resize(image, [60,60]) # now becomes (60,60,3)\n",
        "  image = tf.expand_dims(image, axis = 0) # now becomes (1,60,60,3)\n",
        "  # note that this is the same as the output shape of inputlayer\n",
        "\n",
        "  predictions = model.predict(image) # output a list of results[0.00005, ..., 0.99]\n",
        "  prediction = np.argmax(predictions)\n",
        "\n",
        "  return prediction \n",
        "\n",
        "if __name__ =='__main__':\n",
        "  img_path = \"/content/German-dataset/Test/2/00092.png\"\n",
        "  img_path = \"/content/German-dataset/Test/0/00807.png\"\n",
        "  model = tf.keras.models.load_model('./Models')\n",
        "  prediction = predict_with_model(model, img_path)\n",
        "  print(\"Prediction is\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpZwd4pqqHql",
        "outputId": "f0ff3c45-f1e1-46b8-9cb6-88b299771fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction is 0\n"
          ]
        }
      ]
    }
  ]
}